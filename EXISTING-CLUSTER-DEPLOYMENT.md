# åœ¨å·²æœ‰é›†ç¾¤ä¸Šéƒ¨ç½²ç›‘æ§æ ˆ - å®Œæ•´æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜åœ¨**å·²æœ‰ EKS é›†ç¾¤**ï¼ˆé€šè¿‡ CDK æˆ–å…¶ä»– IaC å·¥å…·åˆ›å»ºï¼‰ä¸Šï¼Œä½¿ç”¨ **ArgoCD** éƒ¨ç½² **Prometheus + Loki + Promtail** ç›‘æ§æ ˆçš„å®Œæ•´æ­¥éª¤å’Œæ³¨æ„äº‹é¡¹ã€‚

**é€‚ç”¨åœºæ™¯**ï¼š

- âœ… EKS é›†ç¾¤å·²é€šè¿‡ CDK/CloudFormation/Pulumi åˆ›å»º
- âœ… ArgoCD å·²å®‰è£…å¹¶è¿è¡Œ
- âœ… ALB Controller å·²å®‰è£…
- âœ… EBS CSI Driver å·²å®‰è£…
- âœ… å·²æœ‰å…¶ä»–åº”ç”¨é€šè¿‡ ArgoCD ç®¡ç†

---

## âš ï¸ é‡è¦å‰ææ£€æŸ¥

åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®è®¤ä»¥ä¸‹ä¿¡æ¯ï¼š

### 1. é›†ç¾¤ä¿¡æ¯

```bash
# è·å–é›†ç¾¤åç§°å’ŒåŒºåŸŸ
aws eks list-clusters --region <your-region>

# è·å–é›†ç¾¤è¯¦ç»†ä¿¡æ¯
aws eks describe-cluster --name <cluster-name> --region <your-region>

# æ£€æŸ¥ OIDC Providerï¼ˆIRSA å¿…éœ€ï¼‰
aws eks describe-cluster --name <cluster-name> --region <your-region> \
  --query 'cluster.identity.oidc.issuer' --output text
```

**éœ€è¦è®°å½•çš„ä¿¡æ¯**ï¼š

- é›†ç¾¤åç§°ï¼š`<cluster-name>`
- AWS åŒºåŸŸï¼š`<region>`ï¼ˆå¦‚ `ap-southeast-2`ï¼‰
- OIDC Provider URLï¼š`https://oidc.eks.<region>.amazonaws.com/id/<id>`

### 2. è®¿é—®æƒé™

```bash
# æ£€æŸ¥ kubectl è®¿é—®
kubectl cluster-info

# æ£€æŸ¥ AWS æƒé™
aws sts get-caller-identity

# æ£€æŸ¥é›†ç¾¤è®¿é—®
kubectl get nodes
```

### 3. ArgoCD çŠ¶æ€

```bash
# æ£€æŸ¥ ArgoCD æ˜¯å¦è¿è¡Œ
kubectl get pods -n argocd

# æ£€æŸ¥ ArgoCD æœåŠ¡
kubectl get svc -n argocd

# è·å– ArgoCD è®¿é—®åœ°å€
kubectl get svc -n argocd argocd-server -o jsonpath='{.status.loadBalancer.ingress[0].hostname}'
```

### 4. Git ä»“åº“è®¿é—®

ç¡®ä¿ ArgoCD å¯ä»¥è®¿é—®ä½ çš„ Git ä»“åº“ï¼š

```bash
# åœ¨ ArgoCD UI ä¸­æ£€æŸ¥
# Settings â†’ Repositories â†’ ç¡®è®¤ä»“åº“å·²è¿æ¥
```

---

## ğŸ” å…³é”®èµ„æºæ£€æŸ¥æ¸…å•

åœ¨éƒ¨ç½²å‰ï¼Œå¿…é¡»æ£€æŸ¥ä»¥ä¸‹èµ„æºçš„çŠ¶æ€ï¼š

### 1. EBS CSI Driverï¼ˆå¿…é¡»å·²å®‰è£…ï¼‰

**æ£€æŸ¥æ–¹æ³•**ï¼š

```bash
# æ–¹æ³• 1: æ£€æŸ¥ EKS Add-on
aws eks describe-addon \
  --cluster-name <cluster-name> \
  --addon-name aws-ebs-csi-driver \
  --region <region> \
  --query 'addon.status' --output text

# æ–¹æ³• 2: æ£€æŸ¥ Pod
kubectl get pods -n kube-system | grep ebs-csi

# åº”è¯¥çœ‹åˆ°ï¼š
# ebs-csi-controller-xxx    Running
# ebs-csi-node-xxx          Running
```

**å¦‚æœæœªå®‰è£…**ï¼š

```bash
# å®‰è£… EBS CSI Driverï¼ˆä½¿ç”¨ EKS Add-onï¼Œæ¨èï¼‰
aws eks create-addon \
  --cluster-name <cluster-name> \
  --addon-name aws-ebs-csi-driver \
  --addon-version v1.32.0-eksbuild.1 \
  --region <region>

# æˆ–ä½¿ç”¨ Helm
helm repo add aws-ebs-csi-driver https://kubernetes-sigs.github.io/aws-ebs-csi-driver
helm install aws-ebs-csi-driver aws-ebs-csi-driver/aws-ebs-csi-driver \
  --namespace kube-system
```

**é‡è¦**ï¼šå¦‚æœ CSI Driver å·²å­˜åœ¨ï¼Œ**ä¸éœ€è¦**é€šè¿‡ Terraform åˆ›å»ºã€‚

### 2. StorageClass gp3ï¼ˆå¿…é¡»å­˜åœ¨ï¼‰

**æ£€æŸ¥æ–¹æ³•**ï¼š

```bash
# æ£€æŸ¥ StorageClass
kubectl get storageclass gp3

# æ£€æŸ¥é…ç½®
kubectl get storageclass gp3 -o yaml
```

**å¿…é¡»çš„é…ç½®**ï¼š

```yaml
provisioner: ebs.csi.aws.com
parameters:
  type: gp3
volumeBindingMode: WaitForFirstConsumer # æ¨è
```

**å¦‚æœä¸å­˜åœ¨æˆ–é…ç½®é”™è¯¯**ï¼š

```bash
# åˆ›å»º gp3 StorageClass
cat <<EOF | kubectl apply -f -
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: gp3
provisioner: ebs.csi.aws.com
parameters:
  type: gp3
  fsType: ext4
volumeBindingMode: WaitForFirstConsumer
allowVolumeExpansion: true
EOF
```

**é‡è¦**ï¼šç¡®ä¿ StorageClass çš„ `provisioner` æ˜¯ `ebs.csi.aws.com`ï¼Œå¦åˆ™ PVC æ— æ³•ç»‘å®šã€‚

### 3. OIDC Providerï¼ˆIRSA å¿…éœ€ï¼‰

**æ£€æŸ¥æ–¹æ³•**ï¼š

```bash
# è·å– OIDC Provider URL
OIDC_URL=$(aws eks describe-cluster --name <cluster-name> --region <region> \
  --query 'cluster.identity.oidc.issuer' --output text | sed 's|https://||')

# æ£€æŸ¥ OIDC Provider æ˜¯å¦å·²å…³è”åˆ° IAM
aws iam list-open-id-connect-providers | grep $OIDC_URL
```

**å¦‚æœæœªå…³è”**ï¼š

```bash
# å…³è” OIDC Provider
eksctl utils associate-iam-oidc-provider \
  --cluster <cluster-name> \
  --region <region> \
  --approve
```

### 4. èŠ‚ç‚¹èµ„æº

**æ£€æŸ¥æ–¹æ³•**ï¼š

```bash
# æ£€æŸ¥èŠ‚ç‚¹æ•°é‡å’Œèµ„æº
kubectl get nodes -o custom-columns=NAME:.metadata.name,CPU:.status.capacity.cpu,MEMORY:.status.capacity.memory

# æ£€æŸ¥èŠ‚ç‚¹èµ„æºä½¿ç”¨
kubectl top nodes 2>/dev/null || echo "Metrics server not available"
```

**å»ºè®®**ï¼š

- è‡³å°‘ 2 ä¸ªèŠ‚ç‚¹
- æ¯ä¸ªèŠ‚ç‚¹è‡³å°‘ 2 CPUã€4GB å†…å­˜
- å¯¹äºç”Ÿäº§ç¯å¢ƒï¼Œå»ºè®® 4 ä¸ªèŠ‚ç‚¹æˆ–æ›´å¤š

---

## ğŸš€ å®Œæ•´éƒ¨ç½²æ­¥éª¤

### Step 0: å‡†å¤‡å·¥ä½œ

#### 0.1 å…‹éš†æˆ–å‡†å¤‡ä»£ç ä»“åº“

```bash
# å¦‚æœä½¿ç”¨ Git ä»“åº“
git clone <your-repo-url>
cd monitoring-stack

# æˆ–ç¡®ä¿ä»£ç å·²æäº¤åˆ° Git ä»“åº“ï¼ˆArgoCD éœ€è¦è®¿é—®ï¼‰
```

#### 0.2 é…ç½® kubectl

```bash
# é…ç½® kubectl è¿æ¥åˆ°é›†ç¾¤
aws eks update-kubeconfig --name <cluster-name> --region <region>

# éªŒè¯è¿æ¥
kubectl cluster-info
kubectl get nodes
```

#### 0.3 æ£€æŸ¥ ArgoCD Git ä»“åº“é…ç½®

åœ¨ ArgoCD UI ä¸­ï¼š

1. è¿›å…¥ **Settings** â†’ **Repositories**
2. ç¡®è®¤ä½ çš„ Git ä»“åº“å·²æ·»åŠ 
3. å¦‚æœä½¿ç”¨ç§æœ‰ä»“åº“ï¼Œç¡®ä¿è®¤è¯ä¿¡æ¯æ­£ç¡®

---

### Step 1: åˆ›å»º AWS èµ„æºï¼ˆS3 + IAMï¼‰

ç”±äºé›†ç¾¤å·²å­˜åœ¨ï¼Œæˆ‘ä»¬åªéœ€è¦åˆ›å»ºç›‘æ§æ ˆæ‰€éœ€çš„ AWS èµ„æºï¼š

- S3 Bucketï¼ˆç”¨äº Loki å­˜å‚¨ï¼‰
- IAM Role å’Œ Policyï¼ˆç”¨äº IRSAï¼‰

#### 1.1 ä½¿ç”¨ AWS CDK TypeScript åˆ›å»ºèµ„æºï¼ˆæ¨èï¼‰

**åˆ›å»º CDK é¡¹ç›®ç»“æ„**ï¼š

```bash
# åˆ›å»º CDK é¡¹ç›®ç›®å½•
mkdir -p cdk-monitoring-stack
cd cdk-monitoring-stack

# åˆå§‹åŒ– CDK TypeScript é¡¹ç›®
cdk init app --language typescript

# å®‰è£…å¿…è¦çš„ä¾èµ–ï¼ˆCDK v2 ä½¿ç”¨ aws-cdk-libï¼‰
npm install aws-cdk-lib constructs
```

**åˆ›å»º CDK Stack** (`lib/cdk-monitoring-stack-stack.ts`)ï¼š

```typescript
import * as cdk from "aws-cdk-lib";
import * as s3 from "aws-cdk-lib/aws-s3";
import * as iam from "aws-cdk-lib/aws-iam";
import { Construct } from "constructs";

export interface MonitoringStackProps extends cdk.StackProps {
  clusterName: string;
  oidcProviderArn: string;
  oidcIssuerUrl: string;
  retentionDays?: number;
}

export class MonitoringStackStack extends cdk.Stack {
  public readonly lokiBucket: s3.Bucket;
  public readonly lokiRole: iam.Role;

  constructor(scope: Construct, id: string, props: MonitoringStackProps) {
    super(scope, id, props);

    const {
      clusterName,
      oidcProviderArn,
      oidcIssuerUrl,
      retentionDays = 30,
    } = props;

    // 1. åˆ›å»º S3 Bucket for Loki
    this.lokiBucket = new s3.Bucket(this, "LokiStorageBucket", {
      bucketName: `${clusterName}-loki-storage-${this.account.substring(0, 8)}`,
      versioned: true,
      encryption: s3.BucketEncryption.S3_MANAGED,
      blockPublicAccess: s3.BlockPublicAccess.BLOCK_ALL,
      removalPolicy: cdk.RemovalPolicy.DESTROY, // å…è®¸åˆ é™¤éç©º bucket
      autoDeleteObjects: true, // è‡ªåŠ¨åˆ é™¤å¯¹è±¡
      lifecycleRules: [
        {
          id: "delete-old-logs",
          enabled: true,
          expiration: cdk.Duration.days(retentionDays),
          noncurrentVersionExpiration: cdk.Duration.days(retentionDays),
        },
      ],
    });

    // 2. åˆ›å»º IAM Policy for S3 access
    const lokiS3Policy = new iam.Policy(this, "LokiS3AccessPolicy", {
      policyName: `${clusterName}-loki-s3-access-policy`,
      statements: [
        new iam.PolicyStatement({
          effect: iam.Effect.ALLOW,
          actions: [
            "s3:PutObject",
            "s3:GetObject",
            "s3:DeleteObject",
            "s3:ListBucket",
          ],
          resources: [
            this.lokiBucket.bucketArn,
            `${this.lokiBucket.bucketArn}/*`,
          ],
        }),
      ],
    });

    // 3. åˆ›å»º IAM Role for IRSA
    const oidcProvider = iam.OpenIdConnectProvider.fromOpenIdConnectProviderArn(
      this,
      "OidcProvider",
      oidcProviderArn
    );

    const oidcIssuer = oidcIssuerUrl.replace("https://", "");

    this.lokiRole = new iam.Role(this, "LokiS3Role", {
      roleName: `${clusterName}-loki-s3-role`,
      assumedBy: new iam.WebIdentityPrincipal(
        oidcProvider.openIdConnectProviderArn,
        {
          StringEquals: {
            [`${oidcIssuer}:sub`]:
              "system:serviceaccount:monitoring:loki-s3-service-account",
            [`${oidcIssuer}:aud`]: "sts.amazonaws.com",
          },
        }
      ),
    });

    // 4. é™„åŠ ç­–ç•¥åˆ°è§’è‰²
    this.lokiRole.attachInlinePolicy(lokiS3Policy);

    // 5. è¾“å‡ºå€¼
    new cdk.CfnOutput(this, "LokiBucketName", {
      value: this.lokiBucket.bucketName,
      exportName: `${clusterName}-loki-bucket-name`,
    });

    new cdk.CfnOutput(this, "LokiRoleArn", {
      value: this.lokiRole.roleArn,
      exportName: `${clusterName}-loki-role-arn`,
    });

    new cdk.CfnOutput(this, "AwsRegion", {
      value: this.region,
      exportName: `${clusterName}-aws-region`,
    });
  }
}
```

**æ›´æ–° CDK App** (`bin/cdk-monitoring-stack.ts`)ï¼š

```typescript
#!/usr/bin/env node
import "source-map-support/register";
import * as cdk from "aws-cdk-lib";
import { MonitoringStackStack } from "../lib/cdk-monitoring-stack-stack";

const app = new cdk.App();

// ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶è·å–é›†ç¾¤ä¿¡æ¯
const clusterName = process.env.CLUSTER_NAME || "your-cluster-name";
const oidcProviderArn =
  process.env.OIDC_PROVIDER_ARN ||
  "arn:aws:iam::ACCOUNT:oidc-provider/oidc.eks.REGION.amazonaws.com/id/ID";
const oidcIssuerUrl =
  process.env.OIDC_ISSUER_URL || "https://oidc.eks.REGION.amazonaws.com/id/ID";
const retentionDays = parseInt(process.env.RETENTION_DAYS || "30");

new MonitoringStackStack(app, "MonitoringStackStack", {
  env: {
    account: process.env.CDK_DEFAULT_ACCOUNT,
    region: process.env.CDK_DEFAULT_REGION || "ap-southeast-2",
  },
  clusterName,
  oidcProviderArn,
  oidcIssuerUrl,
  retentionDays,
});
```

**åˆ›å»ºé…ç½®æ–‡ä»¶** (`.env.example`)ï¼š

```bash
# é›†ç¾¤ä¿¡æ¯
CLUSTER_NAME=your-cluster-name
CDK_DEFAULT_REGION=ap-southeast-2
CDK_DEFAULT_ACCOUNT=123456789012

# OIDC Provider ä¿¡æ¯ï¼ˆä»é›†ç¾¤è·å–ï¼‰
OIDC_PROVIDER_ARN=arn:aws:iam::123456789012:oidc-provider/oidc.eks.ap-southeast-2.amazonaws.com/id/ABCDEFGHIJKLMNOP
OIDC_ISSUER_URL=https://oidc.eks.ap-southeast-2.amazonaws.com/id/ABCDEFGHIJKLMNOP

# Loki é…ç½®
RETENTION_DAYS=30
```

#### 1.2 éƒ¨ç½² CDK Stack

```bash
# 1. è·å– OIDC Provider ä¿¡æ¯
export CLUSTER_NAME="<your-cluster-name>"
export AWS_REGION="<your-region>"

# è·å– OIDC Issuer URL
export OIDC_ISSUER_URL=$(aws eks describe-cluster \
  --name $CLUSTER_NAME \
  --region $AWS_REGION \
  --query 'cluster.identity.oidc.issuer' \
  --output text)

# è·å– OIDC Provider ARN
export OIDC_PROVIDER_ARN=$(aws iam list-open-id-connect-providers \
  --query "OpenIDConnectProviderList[?contains(Url, '$(echo $OIDC_ISSUER_URL | sed 's|https://||')')].Arn" \
  --output text)

# 2. è®¾ç½®ç¯å¢ƒå˜é‡
export CDK_DEFAULT_REGION=$AWS_REGION
export CDK_DEFAULT_ACCOUNT=$(aws sts get-caller-identity --query Account --output text)

# 3. æ„å»ºå’Œéƒ¨ç½²
cd cdk-monitoring-stack
npm install
npm run build
cdk synth
cdk deploy --require-approval never

# 4. è·å–è¾“å‡ºå€¼
export BUCKET_NAME=$(aws cloudformation describe-stacks \
  --stack-name MonitoringStackStack \
  --query 'Stacks[0].Outputs[?OutputKey==`LokiBucketName`].OutputValue' \
  --output text)

export ROLE_ARN=$(aws cloudformation describe-stacks \
  --stack-name MonitoringStackStack \
  --query 'Stacks[0].Outputs[?OutputKey==`LokiRoleArn`].OutputValue' \
  --output text)

echo "S3 Bucket: $BUCKET_NAME"
echo "IAM Role ARN: $ROLE_ARN"
echo "AWS Region: $AWS_REGION"
```

#### 1.3 è®°å½•è¾“å‡ºå€¼

```bash
# ä¿å­˜è¾“å‡ºå€¼ä¾›åç»­ä½¿ç”¨
cat > .env <<EOF
BUCKET_NAME=$BUCKET_NAME
ROLE_ARN=$ROLE_ARN
AWS_REGION=$AWS_REGION
EOF

source .env
```

**é€‰é¡¹ Bï¼šæ‰‹åŠ¨åˆ›å»º AWS èµ„æºï¼ˆå¦‚æœä¸æƒ³ä½¿ç”¨ CDKï¼‰**

å¦‚æœä¸æƒ³ä½¿ç”¨ CDKï¼Œå¯ä»¥æ‰‹åŠ¨åˆ›å»ºï¼ˆå‚è€ƒåŸæ–‡æ¡£ä¸­çš„æ‰‹åŠ¨åˆ›å»ºæ­¥éª¤ï¼‰ã€‚

---

### Step 2: åˆ›å»º Kubernetes èµ„æº

#### 2.1 åˆ›å»º Namespaceï¼ˆå¯é€‰ï¼ŒArgoCD å¯ä»¥è‡ªåŠ¨åˆ›å»ºï¼‰

```bash
# åˆ›å»º monitoring namespaceï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
kubectl create namespace monitoring --dry-run=client -o yaml | kubectl apply -f -
```

**æ³¨æ„**ï¼šå¦‚æœ ArgoCD Application é…ç½®äº† `CreateNamespace=true`ï¼Œå¯ä»¥è·³è¿‡æ­¤æ­¥éª¤ã€‚

#### 2.2 åˆ›å»º ServiceAccount å¹¶é…ç½® IRSA

```bash
# åˆ›å»º ServiceAccount
kubectl create serviceaccount loki-s3-service-account -n monitoring

# é…ç½® IRSA æ³¨è§£ï¼ˆä½¿ç”¨ Step 1.3 ä¸­è·å–çš„ ROLE_ARNï¼‰
kubectl annotate serviceaccount loki-s3-service-account -n monitoring \
  eks.amazonaws.com/role-arn=${ROLE_ARN} --overwrite

# éªŒè¯
kubectl get serviceaccount loki-s3-service-account -n monitoring -o yaml
```

**é‡è¦**ï¼š

- ServiceAccount åç§°å¿…é¡»æ˜¯ `loki-s3-service-account`
- Namespace å¿…é¡»æ˜¯ `monitoring`
- IAM Role ARN å¿…é¡»æ­£ç¡®

---

### Step 3: æ›´æ–° Values æ–‡ä»¶é…ç½®

#### 3.1 æ›´æ–° Loki Values æ–‡ä»¶

ç¼–è¾‘ `monitoring/values/loki-values-s3.yaml`ï¼Œä½¿ç”¨ä» Step 1.3 è·å–çš„å€¼ï¼š

```yaml
# Loki configuration - Using default SimpleScalable mode (requires S3)
# Use default SimpleScalable mode
deploymentMode: SimpleScalable

# Loki storage configuration - AWS S3
loki:
  auth_enabled: false
  # Schema configuration (required for SimpleScalable mode)
  # Loki 3.0.0 requires schema v13 and tsdb index type
  schemaConfig:
    configs:
      - from: "2020-10-24"
        store: tsdb # å¿…é¡»
        object_store: s3
        schema: v13 # å¿…é¡»
        index:
          prefix: index_
          period: 24h
  # Disable structured metadata to avoid validation errors
  limits_config:
    allow_structured_metadata: false
  storage:
    type: s3
    bucketNames:
      chunks: <BUCKET_NAME> # ä» Step 1.3 è·å–ï¼Œä¾‹å¦‚: eks-test-loki-storage-565c7d68
      ruler: <BUCKET_NAME> # ä» Step 1.3 è·å–
    s3:
      endpoint: s3.amazonaws.com
      region: <AWS_REGION> # ä» Step 1.3 è·å–ï¼Œä¾‹å¦‚: ap-southeast-2
      s3ForcePathStyle: false
      # IRSA ä¼šè‡ªåŠ¨å¤„ç†è®¤è¯ï¼Œæ— éœ€é…ç½® accessKeyId å’Œ secretAccessKey

# Persistent storage (for index, not log data)
# For SimpleScalable mode, need to configure persistence for each component
persistence:
  enabled: true
  storageClassName: gp3
  size: 10Gi

# SimpleScalable mode component persistence configuration
simpleScalable:
  backend:
    persistence:
      enabled: true
      storageClassName: gp3
      size: 10Gi
      # å¿…é¡»é…ç½® volumeClaimTemplateï¼Œç¡®ä¿ StatefulSet ä½¿ç”¨æ­£ç¡®çš„ StorageClass
      volumeClaimTemplate:
        spec:
          storageClassName: gp3
  write:
    persistence:
      enabled: true
      storageClassName: gp3
      size: 10Gi
      # å¿…é¡»é…ç½® volumeClaimTemplate
      volumeClaimTemplate:
        spec:
          storageClassName: gp3

# ServiceAccount configuration (if using IRSA)
serviceAccount:
  create: false # ä¸è‡ªåŠ¨åˆ›å»ºï¼Œä½¿ç”¨æ‰‹åŠ¨åˆ›å»ºçš„ï¼ˆStep 2.2ï¼‰
  name: loki-s3-service-account # å¿…é¡»ä¸ Step 2.2 ä¸­çš„åç§°ä¸€è‡´

# Cache components configuration
# Reduce resource requests to fit within node capacity
chunksCache:
  enabled: true
  # Reduce Memcached allocated memory from default 8192MB to 1024MB (1GB)
  # This should match the Kubernetes memory limits
  allocatedMemory: 1024 # MB, reduced from default 8192MB
  maxItemMemory: 5 # MB, maximum item size
  connectionLimit: 16384
  resources:
    requests:
      cpu: 500m
      memory: 1Gi # Reduced from default 9830Mi to fit node capacity (~3.8GB)
    limits:
      memory: 2Gi # Allow some burst but limit to prevent OOM

resultsCache:
  enabled: true
  resources:
    requests:
      cpu: 100m
      memory: 512Mi
    limits:
      memory: 1Gi
```

**ä½¿ç”¨è„šæœ¬è‡ªåŠ¨æ›´æ–°**ï¼š

```bash
# å¦‚æœä½¿ç”¨ CDK
cd cdk-monitoring-stack
source .env

# æ›´æ–° loki-values-s3.yaml
sed -i.bak \
  -e "s|chunks:.*|chunks: ${BUCKET_NAME}|g" \
  -e "s|ruler:.*|ruler: ${BUCKET_NAME}|g" \
  -e "s|region:.*|region: ${AWS_REGION}|g" \
  ../monitoring/values/loki-values-s3.yaml
```

#### 3.2 Prometheus Values æ–‡ä»¶é…ç½®

ç¡®ä¿ `monitoring/values/prometheus-values.yaml` é…ç½®æ­£ç¡®ï¼š

```yaml
# Prometheus configuration
prometheus:
  enabled: true
  prometheusSpec:
    retention: 30d
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: gp3 # å¿…é¡»
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 100Gi
    serviceMonitorSelectorNilUsesHelmValues: false
    podMonitorSelectorNilUsesHelmValues: false
    ruleSelectorNilUsesHelmValues: false

# Grafana configuration
grafana:
  enabled: true
  # Use secret to configure admin account
  secret:
    admin-user: admin
    admin-password: "admin" # ç”Ÿäº§ç¯å¢ƒè¯·ä½¿ç”¨å¼ºå¯†ç 
  persistence:
    enabled: true
    storageClassName: gp3 # å¿…é¡»
    size: 10Gi
  service:
    type: ClusterIP # ä½¿ç”¨ ClusterIPï¼ŒLoadBalancer ç”±å…¶ä»–æ–¹å¼ç®¡ç†
  # é‡è¦ï¼šä½¿ç”¨ additionalDataSources è€Œä¸æ˜¯ datasources
  # kube-prometheus-stack ä¼šè‡ªåŠ¨åˆ›å»º Prometheus æ•°æ®æº
  additionalDataSources:
    - name: Loki
      type: loki
      access: proxy
      url: http://loki.monitoring.svc:3100
      isDefault: false # Prometheus å·²ç”± kube-prometheus-stack è®¾ç½®ä¸ºé»˜è®¤
      editable: true
  # Pre-installed dashboards
  dashboards:
    default:
      kubernetes-cluster-monitoring:
        gnetId: 7249
        revision: 1
        datasource: Prometheus
      node-exporter:
        gnetId: 1860
        revision: 27
        datasource: Prometheus
      nginx-exporter:
        gnetId: 12708
        revision: 1
        datasource: Prometheus
      loki-logs:
        gnetId: 13639
        revision: 1
        datasource: Loki

# Enable other components
alertmanager:
  enabled: true
nodeExporter:
  enabled: true
kubeStateMetrics:
  enabled: true
defaultRules:
  create: true
```

#### 3.3 Promtail Values æ–‡ä»¶é…ç½®

ç¡®ä¿ `monitoring/values/promtail-values.yaml` é…ç½®æ­£ç¡®ï¼š

```yaml
# Promtail configuration
# Configure Promtail to connect to Loki
config:
  clients:
    - url: http://loki.monitoring.svc:3100/loki/api/v1/push
```

#### 3.4 æäº¤æ›´æ”¹åˆ° Git

```bash
# æäº¤æ›´æ–°çš„ values æ–‡ä»¶
git add monitoring/values/loki-values-s3.yaml
git add monitoring/values/prometheus-values.yaml
git add monitoring/values/promtail-values.yaml
git commit -m "chore: Update monitoring stack values files for existing cluster"
git push origin main
```

**é‡è¦**ï¼šArgoCD ä¼šä» Git ä»“åº“è¯»å–é…ç½®ï¼Œå¿…é¡»æäº¤æ›´æ”¹ã€‚

---

### Step 4: éªŒè¯ ArgoCD é…ç½®

#### 4.1 æ£€æŸ¥ ArgoCD Application é…ç½®

ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶é…ç½®æ­£ç¡®ï¼š

**`monitoring/argocd/prometheus.yaml`**ï¼š

```yaml
spec:
  sources: # æ³¨æ„ï¼šä½¿ç”¨ sourcesï¼ˆå¤æ•°ï¼‰
    - repoURL: https://prometheus-community.github.io/helm-charts
      chart: kube-prometheus-stack
      targetRevision: 60.0.0
      helm:
        valueFiles:
          - $values/monitoring/values/prometheus-values.yaml
    - repoURL: https://github.com/<your-org>/<your-repo>.git # ä½ çš„ Git ä»“åº“
      targetRevision: main
      ref: values # æ ‡è¯†è¿™æ˜¯ values æ–‡ä»¶çš„æ¥æº
```

**`monitoring/argocd/loki.yaml`**ï¼š

```yaml
spec:
  sources: # æ³¨æ„ï¼šä½¿ç”¨ sourcesï¼ˆå¤æ•°ï¼‰
    - repoURL: https://grafana.github.io/helm-charts
      chart: loki
      targetRevision: 6.0.0
      helm:
        valueFiles:
          - $values/monitoring/values/loki-values-s3.yaml
    - repoURL: https://github.com/<your-org>/<your-repo>.git # ä½ çš„ Git ä»“åº“
      targetRevision: main
      ref: values
```

**`monitoring/argocd/promtail.yaml`**ï¼š

```yaml
spec:
  sources: # æ³¨æ„ï¼šä½¿ç”¨ sourcesï¼ˆå¤æ•°ï¼‰
    - repoURL: https://grafana.github.io/helm-charts
      chart: promtail
      targetRevision: 6.0.0
      helm:
        valueFiles:
          - $values/monitoring/values/promtail-values.yaml
    - repoURL: https://github.com/<your-org>/<your-repo>.git # ä½ çš„ Git ä»“åº“
      targetRevision: main
      ref: values
```

**å…³é”®ç‚¹**ï¼š

- âœ… ä½¿ç”¨ `sources`ï¼ˆå¤æ•°ï¼‰è€Œä¸æ˜¯ `source`
- âœ… ç¬¬ä¸€ä¸ª source æ˜¯ Helm Chart ä»“åº“
- âœ… ç¬¬äºŒä¸ª source æ˜¯ Git ä»“åº“ï¼Œç”¨äºæä¾› values æ–‡ä»¶
- âœ… `ref: values` æ ‡è¯† Git ä»“åº“ç”¨äº values æ–‡ä»¶

#### 4.2 éªŒè¯ Git ä»“åº“ URL

ç¡®ä¿æ‰€æœ‰ Application æ–‡ä»¶ä¸­çš„ Git ä»“åº“ URL æ­£ç¡®ï¼š

```bash
# æ£€æŸ¥ Git ä»“åº“ URL
grep -r "repoURL.*github.com" monitoring/argocd/

# åº”è¯¥æ˜¾ç¤ºä½ çš„ Git ä»“åº“ URL
```

---

### Step 5: éƒ¨ç½²åº”ç”¨ï¼ˆæŒ‰é¡ºåºï¼‰

#### 5.1 éƒ¨ç½² Lokiï¼ˆç¬¬ä¸€æ­¥ï¼‰

```bash
# åº”ç”¨ Loki Application
kubectl apply -f monitoring/argocd/loki.yaml

# ç­‰å¾… ArgoCD åŒæ­¥
kubectl wait --for=condition=Synced application/loki -n argocd --timeout=300s

# æ£€æŸ¥ Application çŠ¶æ€
kubectl get application loki -n argocd

# æ£€æŸ¥ Pod çŠ¶æ€
kubectl get pods -n monitoring -l app.kubernetes.io/name=loki -w
```

**é¢„æœŸç»“æœ**ï¼š

- Application çŠ¶æ€ï¼š`Synced`ã€`Healthy`
- Loki Pods åº”è¯¥å¤„äº `Running` çŠ¶æ€
- å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´

**å¸¸è§é—®é¢˜**ï¼š

- å¦‚æœ Pod å¤„äº `Pending`ï¼Œæ£€æŸ¥ PVC æ˜¯å¦ç»‘å®š
- å¦‚æœ Pod å¤„äº `CrashLoopBackOff`ï¼Œæ£€æŸ¥æ—¥å¿—

#### 5.2 éƒ¨ç½² Promtailï¼ˆç¬¬äºŒæ­¥ï¼‰

```bash
# åº”ç”¨ Promtail Application
kubectl apply -f monitoring/argocd/promtail.yaml

# ç­‰å¾…åŒæ­¥
kubectl wait --for=condition=Synced application/promtail -n argocd --timeout=300s

# æ£€æŸ¥çŠ¶æ€
kubectl get pods -n monitoring -l app.kubernetes.io/name=promtail
```

#### 5.3 éƒ¨ç½² Prometheusï¼ˆç¬¬ä¸‰æ­¥ï¼‰

```bash
# åº”ç”¨ Prometheus Application
kubectl apply -f monitoring/argocd/prometheus.yaml

# ç­‰å¾…åŒæ­¥
kubectl wait --for=condition=Synced application/prometheus -n argocd --timeout=300s

# æ£€æŸ¥çŠ¶æ€
kubectl get pods -n monitoring -l app.kubernetes.io/name=prometheus
kubectl get pods -n monitoring -l app.kubernetes.io/name=grafana
```

---

### Step 6: éªŒè¯éƒ¨ç½²

#### 6.1 æ£€æŸ¥æ‰€æœ‰ Pod çŠ¶æ€

```bash
# æ£€æŸ¥æ‰€æœ‰ç›‘æ§ç›¸å…³çš„ Pod
kubectl get pods -n monitoring

# åº”è¯¥çœ‹åˆ°ï¼š
# - loki-* Pods: Running
# - promtail-* Pods: Running
# - prometheus-* Pods: Running
# - grafana-* Pods: Running
# - alertmanager-* Pods: Running
```

#### 6.2 æ£€æŸ¥ PVC çŠ¶æ€

```bash
# æ£€æŸ¥ PVC
kubectl get pvc -n monitoring

# æ‰€æœ‰ PVC åº”è¯¥æ˜¯ Bound çŠ¶æ€
# å¦‚æœçœ‹åˆ° Pendingï¼Œæ£€æŸ¥ï¼š
# 1. StorageClass gp3 æ˜¯å¦å­˜åœ¨
# 2. EBS CSI Driver æ˜¯å¦è¿è¡Œ
# 3. èŠ‚ç‚¹æ˜¯å¦æœ‰è¶³å¤Ÿèµ„æº
```

#### 6.3 æ£€æŸ¥ ArgoCD Application çŠ¶æ€

```bash
# æ£€æŸ¥æ‰€æœ‰ Application
kubectl get application -n argocd

# åº”è¯¥éƒ½æ˜¯ Synced å’Œ Healthy
```

#### 6.4 æµ‹è¯• Loki åŠŸèƒ½

```bash
# è·å– Loki Gateway åœ°å€
LOKI_GATEWAY=$(kubectl get svc -n monitoring loki-gateway -o jsonpath='{.spec.clusterIP}')

# æµ‹è¯•å†™å…¥æ—¥å¿—
kubectl run -it --rm test-loki --image=curlimages/curl:7.85.0 --restart=Never -- \
  curl -X POST http://${LOKI_GATEWAY}:8080/loki/api/v1/push \
  -H "Content-Type: application/json" \
  -d '{"streams":[{"stream":{"job":"test"},"values":[["'$(date +%s)000000000'","test message"]]}]}'

# æµ‹è¯•æŸ¥è¯¢æ—¥å¿—
kubectl run -it --rm test-loki-query --image=curlimages/curl:7.85.0 --restart=Never -- \
  curl "http://${LOKI_GATEWAY}:8080/loki/api/v1/query?query={job=\"test\"}"
```

#### 6.5 æµ‹è¯• Prometheus åŠŸèƒ½

```bash
# Port-forward Prometheus
kubectl port-forward -n monitoring svc/prometheus-operated 9090:9090

# åœ¨æµè§ˆå™¨ä¸­è®¿é—® http://localhost:9090
# æˆ–æµ‹è¯•æŸ¥è¯¢
curl http://localhost:9090/api/v1/query?query=up
```

#### 6.6 è®¿é—® Grafana

```bash
# è·å– Grafana å¯†ç 
kubectl get secret -n monitoring prometheus-grafana -o jsonpath='{.data.admin-password}' | base64 -d && echo

# Port-forward Grafana
kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80

# åœ¨æµè§ˆå™¨ä¸­è®¿é—® http://localhost:3000
# ç”¨æˆ·å: admin
# å¯†ç : ä»ä¸Šé¢å‘½ä»¤è·å–
```

---

## ğŸ”§ å…³é”®é…ç½®è¯´æ˜

### 1. Loki é…ç½®è¦ç‚¹

#### 1.1 Schema é…ç½®ï¼ˆå¿…é¡»ï¼‰

Loki 3.0.0 è¦æ±‚ä½¿ç”¨ `schema: v13` å’Œ `store: tsdb`ï¼š

```yaml
loki:
  schemaConfig:
    configs:
      - from: "2020-10-24"
        store: tsdb # å¿…é¡»
        object_store: s3
        schema: v13 # å¿…é¡»
        index:
          prefix: index_
          period: 24h
  limits_config:
    allow_structured_metadata: false # å¦‚æœä½¿ç”¨ v13ï¼Œå»ºè®®è®¾ç½®ä¸º false
```

#### 1.2 StorageClass é…ç½®ï¼ˆå¿…é¡»ï¼‰

åœ¨ `simpleScalable` æ¨¡å¼ä¸‹ï¼Œå¿…é¡»ä¸ºæ¯ä¸ªç»„ä»¶é…ç½® `volumeClaimTemplate`ï¼š

```yaml
simpleScalable:
  backend:
    persistence:
      enabled: true
      storageClassName: gp3
      size: 10Gi
      volumeClaimTemplate: # å¿…é¡»
        spec:
          storageClassName: gp3
  write:
    persistence:
      enabled: true
      storageClassName: gp3
      size: 10Gi
      volumeClaimTemplate: # å¿…é¡»
        spec:
          storageClassName: gp3
```

#### 1.3 chunksCache èµ„æºé…ç½®ï¼ˆé‡è¦ï¼‰

å¦‚æœèŠ‚ç‚¹èµ„æºæœ‰é™ï¼Œéœ€è¦å‡å°‘ chunksCache çš„èµ„æºè¯·æ±‚ï¼š

```yaml
chunksCache:
  enabled: true
  allocatedMemory: 1024 # MBï¼Œä»é»˜è®¤ 8192 å‡å°‘
  resources:
    requests:
      cpu: 500m
      memory: 1Gi # ä»é»˜è®¤ 9830Mi å‡å°‘
    limits:
      memory: 2Gi
```

**æ³¨æ„**ï¼š`allocatedMemory` åº”è¯¥å°äºæˆ–ç­‰äº `limits.memory`ã€‚

#### 1.4 S3 Bucket åç§°åŒæ­¥

**é‡è¦é—®é¢˜**ï¼šTerraform ä½¿ç”¨ `random_id` ç”Ÿæˆ bucket åç§°ï¼Œæ¯æ¬¡å¯èƒ½ä¸åŒã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š

1. åœ¨ `loki-values-s3.yaml` ä¸­ä½¿ç”¨å ä½ç¬¦ `${LOKI_S3_BUCKET_NAME}`
2. æˆ–ä½¿ç”¨è„šæœ¬è‡ªåŠ¨æ›´æ–°ï¼ˆ`terraform/update-loki-values.sh`ï¼‰
3. æˆ–æ‰‹åŠ¨æ›´æ–°å¹¶æäº¤åˆ° Git

**éªŒè¯**ï¼š

```bash
# æ£€æŸ¥ ConfigMap ä¸­çš„ bucket åç§°
kubectl get configmap loki -n monitoring -o yaml | grep bucketnames

# åº”è¯¥ä¸ CDK è¾“å‡ºä¸€è‡´
aws cloudformation describe-stacks \
  --stack-name MonitoringStackStack \
  --query 'Stacks[0].Outputs[?OutputKey==`LokiBucketName`].OutputValue' \
  --output text
```

### 2. Prometheus é…ç½®è¦ç‚¹

#### 2.1 Grafana æ•°æ®æºé…ç½®ï¼ˆå¿…é¡»ä½¿ç”¨ additionalDataSourcesï¼‰

**é”™è¯¯æ–¹å¼**ï¼ˆä¼šå¯¼è‡´å†²çªï¼‰ï¼š

```yaml
grafana:
  datasources: # âŒ ä¸è¦ä½¿ç”¨
    datasources.yaml:
      apiVersion: 1
      datasources:
        - name: Prometheus
          isDefault: true
        - name: Loki
          isDefault: false
```

**æ­£ç¡®æ–¹å¼**ï¼š

```yaml
grafana:
  additionalDataSources: # âœ… ä½¿ç”¨è¿™ä¸ª
    - name: Loki
      type: loki
      access: proxy
      url: http://loki.monitoring.svc:3100
      isDefault: false # Prometheus å·²ç”± kube-prometheus-stack è®¾ç½®ä¸ºé»˜è®¤
      editable: true
```

**åŸå› **ï¼š`kube-prometheus-stack` ä¼šè‡ªåŠ¨åˆ›å»º Prometheus æ•°æ®æºï¼Œä½¿ç”¨ `datasources` ä¼šå†²çªã€‚

#### 2.2 StorageClass é…ç½®

```yaml
prometheus:
  prometheusSpec:
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: gp3 # å¿…é¡»
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 100Gi

grafana:
  persistence:
    storageClassName: gp3 # å¿…é¡»
    size: 10Gi
```

### 3. ArgoCD Application é…ç½®è¦ç‚¹

#### 3.1 ä½¿ç”¨ sourcesï¼ˆå¤æ•°ï¼‰æ”¯æŒå¤šä¸ªä»“åº“

```yaml
spec:
  sources: # âœ… ä½¿ç”¨ sourcesï¼ˆå¤æ•°ï¼‰
    - repoURL: https://grafana.github.io/helm-charts # Helm Chart ä»“åº“
      chart: loki
      targetRevision: 6.0.0
      helm:
        valueFiles:
          - $values/monitoring/values/loki-values-s3.yaml
    - repoURL: https://github.com/<your-org>/<your-repo>.git # Git ä»“åº“
      targetRevision: main
      ref: values # æ ‡è¯†è¿™æ˜¯ values æ–‡ä»¶çš„æ¥æº
```

**å…³é”®ç‚¹**ï¼š

- ç¬¬ä¸€ä¸ª sourceï¼šHelm Chart ä»“åº“
- ç¬¬äºŒä¸ª sourceï¼šGit ä»“åº“ï¼ˆæä¾› values æ–‡ä»¶ï¼‰
- `ref: values`ï¼šå‘Šè¯‰ ArgoCD è¿™ä¸ª source ç”¨äº values æ–‡ä»¶

#### 3.2 Sync Policy é…ç½®

```yaml
syncPolicy:
  automated:
    prune: true # è‡ªåŠ¨åˆ é™¤ä¸åœ¨ Git ä¸­çš„èµ„æº
    selfHeal: true # è‡ªåŠ¨ä¿®å¤é…ç½®æ¼‚ç§»
  syncOptions:
    - CreateNamespace=true # è‡ªåŠ¨åˆ›å»º namespace
    - PrunePropagationPolicy=foreground
    - PruneLast=true
    - ServerSideApply=true # ä½¿ç”¨ Server-Side Apply
  retry:
    limit: 5
    backoff:
      duration: 5s
      factor: 2
      maxDuration: 3m
```

---

## âš ï¸ å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

### é—®é¢˜ 1: PVC æ— æ³•ç»‘å®šï¼ˆPendingï¼‰

**é”™è¯¯ä¿¡æ¯**ï¼š

```
Events:
  Warning  FailedBinding  no persistent volumes available for this claim and no storage class is set
```

**åŸå› **ï¼š

1. EBS CSI Driver æœªå®‰è£…æˆ–æœªè¿è¡Œ
2. StorageClass `gp3` ä¸å­˜åœ¨æˆ–é…ç½®é”™è¯¯
3. StorageClass çš„ `provisioner` ä¸æ˜¯ `ebs.csi.aws.com`

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# 1. æ£€æŸ¥ EBS CSI Driver
kubectl get pods -n kube-system | grep ebs-csi

# 2. æ£€æŸ¥ StorageClass
kubectl get storageclass gp3 -o yaml

# 3. å¦‚æœ StorageClass ä¸å­˜åœ¨ï¼Œåˆ›å»ºå®ƒï¼ˆè§ Step 0.2ï¼‰

# 4. å¦‚æœ PVC å·²åˆ›å»ºä½†æœªç»‘å®šï¼Œåˆ é™¤å¹¶è®© ArgoCD é‡æ–°åˆ›å»º
kubectl delete pvc -n monitoring <pvc-name>
# ArgoCD ä¼šè‡ªåŠ¨é‡æ–°åˆ›å»º
```

### é—®é¢˜ 2: Loki Pod CrashLoopBackOff - Schema é”™è¯¯

**é”™è¯¯ä¿¡æ¯**ï¼š

```
CONFIG ERROR: schema v13 is required
CONFIG ERROR: tsdb index type is required
```

**åŸå› **ï¼šLoki values æ–‡ä»¶ä¸­çš„ schema é…ç½®ä¸æ­£ç¡®ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š

1. æ›´æ–° `monitoring/values/loki-values-s3.yaml`ï¼š

```yaml
loki:
  schemaConfig:
    configs:
      - from: "2020-10-24"
        store: tsdb # å¿…é¡»
        object_store: s3
        schema: v13 # å¿…é¡»
```

2. æäº¤åˆ° Gitï¼š

```bash
git add monitoring/values/loki-values-s3.yaml
git commit -m "fix: Update Loki schema to v13 and tsdb"
git push origin main
```

3. è§¦å‘ ArgoCD åŒæ­¥ï¼š

```bash
kubectl annotate application loki -n argocd argocd.argoproj.io/refresh=hard --overwrite
kubectl patch application loki -n argocd --type merge -p '{"operation":{"initiatedBy":{"username":"admin"},"sync":{"revision":"main","prune":true}}}'
```

4. é‡å¯ Loki Podsï¼š

```bash
kubectl delete pod -n monitoring -l app.kubernetes.io/name=loki
```

### é—®é¢˜ 3: Grafana Pod CrashLoopBackOff - æ•°æ®æºå†²çª

**é”™è¯¯ä¿¡æ¯**ï¼š

```
Datasource provisioning error: datasource.yaml config is invalid.
Only one datasource per organization can be marked as default
```

**åŸå› **ï¼šä½¿ç”¨äº† `datasources` è€Œä¸æ˜¯ `additionalDataSources`ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š

1. æ›´æ–° `monitoring/values/prometheus-values.yaml`ï¼š

```yaml
grafana:
  additionalDataSources: # âœ… ä½¿ç”¨è¿™ä¸ª
    - name: Loki
      type: loki
      access: proxy
      url: http://loki.monitoring.svc:3100
      isDefault: false
```

2. åˆ é™¤å†²çªçš„ ConfigMapï¼š

```bash
kubectl delete configmap prometheus-grafana -n monitoring
kubectl delete pod -n monitoring -l app.kubernetes.io/name=grafana
```

3. æäº¤æ›´æ”¹å¹¶è§¦å‘åŒæ­¥ï¼š

```bash
git add monitoring/values/prometheus-values.yaml
git commit -m "fix: Use additionalDataSources for Loki"
git push origin main

kubectl annotate application prometheus -n argocd argocd.argoproj.io/refresh=hard --overwrite
```

### é—®é¢˜ 4: Loki S3 è®¿é—®é”™è¯¯ - MethodNotAllowed

**é”™è¯¯ä¿¡æ¯**ï¼š

```
WebIdentityErr: failed to retrieve credentials
MethodNotAllowed
```

**åŸå› **ï¼šå¯èƒ½æ˜¯ STS endpoint é—®é¢˜ï¼Œä½†é€šå¸¸ä¸å½±å“åŸºæœ¬åŠŸèƒ½ã€‚

**éªŒè¯**ï¼š

```bash
# æµ‹è¯• Loki åŠŸèƒ½
kubectl exec -n monitoring loki-gateway-xxx -- wget -qO- http://localhost:8080/loki/api/v1/labels

# æµ‹è¯•å†™å…¥
kubectl exec -n monitoring loki-gateway-xxx -- wget -qO- --post-data='{"streams":[...]}' http://localhost:8080/loki/api/v1/push
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

- å¦‚æœåŠŸèƒ½æ­£å¸¸ï¼Œå¯ä»¥æš‚æ—¶å¿½ç•¥è¿™äº›é”™è¯¯æ—¥å¿—
- å¦‚æœåŠŸèƒ½å¼‚å¸¸ï¼Œæ£€æŸ¥ IAM Role ä¿¡ä»»ç­–ç•¥å’Œæƒé™

### é—®é¢˜ 5: loki-chunks-cache-0 Pod Pending

**é”™è¯¯ä¿¡æ¯**ï¼š

```
Events:
  Warning  FailedScheduling  0/4 nodes are available: 4 Insufficient memory
```

**åŸå› **ï¼šchunksCache é»˜è®¤éœ€è¦ 9830Mi å†…å­˜ï¼ŒèŠ‚ç‚¹èµ„æºä¸è¶³ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š

1. å‡å°‘èµ„æºè¯·æ±‚ï¼ˆæ¨èï¼‰ï¼š

```yaml
chunksCache:
  enabled: true
  allocatedMemory: 1024 # MB
  resources:
    requests:
      memory: 1Gi # ä» 9830Mi å‡å°‘
    limits:
      memory: 2Gi
```

2. æˆ–ç¦ç”¨ chunksCacheï¼ˆå¦‚æœä¸éœ€è¦ï¼‰ï¼š

```yaml
chunksCache:
  enabled: false
```

3. æäº¤æ›´æ”¹å¹¶åŒæ­¥ï¼š

```bash
git add monitoring/values/loki-values-s3.yaml
git commit -m "fix: Reduce chunksCache resource requests"
git push origin main

kubectl annotate application loki -n argocd argocd.argoproj.io/refresh=hard --overwrite
```

### é—®é¢˜ 6: S3 Bucket åç§°ä¸åŒ¹é…

**é”™è¯¯ä¿¡æ¯**ï¼š

```
NoSuchBucket
```

**åŸå› **ï¼š`loki-values-s3.yaml` ä¸­çš„ bucket åç§°ä¸ Terraform åˆ›å»ºçš„ä¸ä¸€è‡´ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š

1. è·å–æ­£ç¡®çš„ bucket åç§°ï¼š

```bash
# å¦‚æœä½¿ç”¨ CDK
aws cloudformation describe-stacks \
  --stack-name MonitoringStackStack \
  --query 'Stacks[0].Outputs[?OutputKey==`LokiBucketName`].OutputValue' \
  --output text
```

2. æ›´æ–° values æ–‡ä»¶ï¼š

```yaml
bucketNames:
  chunks: <correct-bucket-name>
  ruler: <correct-bucket-name>
```

3. æäº¤å¹¶åŒæ­¥ï¼š

```bash
git add monitoring/values/loki-values-s3.yaml
git commit -m "fix: Update Loki S3 bucket name"
git push origin main

kubectl annotate application loki -n argocd argocd.argoproj.io/refresh=hard --overwrite
```

### é—®é¢˜ 7: ArgoCD Application çŠ¶æ€ Unknown

**é”™è¯¯ä¿¡æ¯**ï¼š

```
Status: Unknown
Message: failed to generate manifest
```

**å¯èƒ½åŸå› **ï¼š

1. Git ä»“åº“æœªé…ç½®æˆ–æ— æ³•è®¿é—®
2. values æ–‡ä»¶è·¯å¾„é”™è¯¯
3. Helm Chart ç‰ˆæœ¬ä¸å­˜åœ¨

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# 1. æ£€æŸ¥ Git ä»“åº“é…ç½®
# åœ¨ ArgoCD UI: Settings â†’ Repositories

# 2. æ£€æŸ¥ Application é…ç½®
kubectl get application loki -n argocd -o yaml

# 3. æ£€æŸ¥ ArgoCD æ—¥å¿—
kubectl logs -n argocd deployment/argocd-repo-server --tail=50

# 4. æ‰‹åŠ¨è§¦å‘åŒæ­¥
kubectl annotate application loki -n argocd argocd.argoproj.io/refresh=hard --overwrite
```

---

## ğŸ“‹ éƒ¨ç½²åéªŒè¯æ¸…å•

éƒ¨ç½²å®Œæˆåï¼ŒéªŒè¯ä»¥ä¸‹å†…å®¹ï¼š

### Kubernetes èµ„æº

- [ ] æ‰€æœ‰ Pod å¤„äº `Running` çŠ¶æ€

  ```bash
  kubectl get pods -n monitoring
  ```

- [ ] æ‰€æœ‰ PVC å¤„äº `Bound` çŠ¶æ€

  ```bash
  kubectl get pvc -n monitoring
  ```

- [ ] ArgoCD Applications çŠ¶æ€ä¸º `Synced` å’Œ `Healthy`
  ```bash
  kubectl get application -n argocd
  ```

### AWS èµ„æº

- [ ] S3 Bucket å­˜åœ¨ä¸”å¯è®¿é—®

  ```bash
  # å¦‚æœä½¿ç”¨ CDK
  BUCKET_NAME=$(aws cloudformation describe-stacks \
    --stack-name MonitoringStackStack \
    --query 'Stacks[0].Outputs[?OutputKey==`LokiBucketName`].OutputValue' \
    --output text)
  aws s3 ls s3://$BUCKET_NAME
  ```

- [ ] IAM Role å­˜åœ¨ä¸”é…ç½®æ­£ç¡®

  ```bash
  aws iam get-role --role-name <cluster-name>-loki-s3-role
  ```

- [ ] ServiceAccount æœ‰æ­£ç¡®çš„ IRSA æ³¨è§£
  ```bash
  kubectl get serviceaccount loki-s3-service-account -n monitoring -o yaml
  ```

### åŠŸèƒ½éªŒè¯

- [ ] Loki å¯ä»¥å†™å…¥å’ŒæŸ¥è¯¢æ—¥å¿—

  ```bash
  # è§ Step 6.4
  ```

- [ ] Prometheus å¯ä»¥æ”¶é›† Metrics

  ```bash
  kubectl port-forward -n monitoring svc/prometheus-operated 9090:9090
  # è®¿é—® http://localhost:9090
  ```

- [ ] Grafana å¯ä»¥è®¿é—®ï¼Œæ•°æ®æºé…ç½®æ­£ç¡®

  ```bash
  kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80
  # è®¿é—® http://localhost:3000
  # æ£€æŸ¥ Data Sources â†’ åº”è¯¥æœ‰ Prometheus å’Œ Loki
  ```

- [ ] Promtail æ­£åœ¨æ”¶é›†æ—¥å¿—
  ```bash
  kubectl logs -n monitoring -l app.kubernetes.io/name=promtail --tail=20
  ```

---

## ğŸ”„ æ›´æ–°å’Œç»´æŠ¤

### æ›´æ–°é…ç½®

1. ä¿®æ”¹ values æ–‡ä»¶
2. æäº¤åˆ° Git
3. ArgoCD ä¼šè‡ªåŠ¨åŒæ­¥ï¼ˆå¦‚æœå¯ç”¨äº† `automated`ï¼‰

### æ‰‹åŠ¨è§¦å‘åŒæ­¥

```bash
# åˆ·æ–°å¹¶åŒæ­¥
kubectl annotate application <app-name> -n argocd argocd.argoproj.io/refresh=hard --overwrite

# æˆ–é€šè¿‡ ArgoCD UI
# ç‚¹å‡» Application â†’ Sync
```

### å›æ»š

```bash
# æŸ¥çœ‹å†å²ç‰ˆæœ¬
kubectl get application <app-name> -n argocd -o yaml | grep revision

# å›æ»šåˆ°ç‰¹å®šç‰ˆæœ¬
kubectl patch application <app-name> -n argocd --type merge -p '{"spec":{"source":{"targetRevision":"<commit-hash>"}}}'
```

---

## ğŸ“š å‚è€ƒæ–‡æ¡£

- [DEBUG.md](./DEBUG.md) - è¯¦ç»†çš„é—®é¢˜æ’æŸ¥æŒ‡å—
- [GRAFANA-USAGE-GUIDE.md](./GRAFANA-USAGE-GUIDE.md) - Grafana ä½¿ç”¨æŒ‡å—
- [CLEANUP-GUIDE.md](./CLEANUP-GUIDE.md) - èµ„æºæ¸…ç†æŒ‡å—
- [Loki Helm Chart](https://github.com/grafana/helm-charts/tree/main/charts/loki)
- [Prometheus Helm Chart](https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack)
- [ArgoCD Documentation](https://argo-cd.readthedocs.io/)

---

## ğŸ¯ æ€»ç»“

åœ¨å·²æœ‰é›†ç¾¤ä¸Šéƒ¨ç½²ç›‘æ§æ ˆçš„å…³é”®ç‚¹ï¼š

1. **æ£€æŸ¥ç°æœ‰èµ„æº**ï¼šEBS CSI Driverã€StorageClassã€OIDC Provider
2. **åªåˆ›å»ºå¿…è¦çš„ AWS èµ„æº**ï¼šS3 Bucketã€IAM Role
3. **æ­£ç¡®é…ç½® IRSA**ï¼šServiceAccount æ³¨è§£å¿…é¡»æ­£ç¡®
4. **ä½¿ç”¨ additionalDataSources**ï¼šé¿å… Grafana æ•°æ®æºå†²çª
5. **æ­£ç¡®é…ç½® Loki Schema**ï¼šv13 + tsdb
6. **é…ç½® volumeClaimTemplate**ï¼šç¡®ä¿ PVC ä½¿ç”¨æ­£ç¡®çš„ StorageClass
7. **ä½¿ç”¨ sourcesï¼ˆå¤æ•°ï¼‰**ï¼šæ”¯æŒå¤šä¸ªä»“åº“æº
8. **åŠæ—¶æäº¤ Git**ï¼šArgoCD ä» Git è¯»å–é…ç½®

éµå¾ªæœ¬æŒ‡å—ï¼Œå¯ä»¥å®‰å…¨åœ°åœ¨å·²æœ‰é›†ç¾¤ä¸Šéƒ¨ç½²ç›‘æ§æ ˆï¼Œé¿å…èµ„æºå†²çªå’Œé…ç½®é”™è¯¯ã€‚
